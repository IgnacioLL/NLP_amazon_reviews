{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Amazon Reviews\n",
    "This dataset contains 3.6 millions reviews in Amazon, this dataset is located in Kaggle a very popular dataset repository. https://www.kaggle.com/bittlingmayer/amazonreviews\n",
    "\n",
    "The code is pretty self-explanatory but if you have any doubts just send me an email to ig.lloret.l@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, GlobalMaxPool1D, Bidirectional,Input,GlobalAveragePooling1D, BatchNormalization, Conv1D,GRU\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "\n",
    "import os\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from pandas import read_table\n",
    "\n",
    "import bz2\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import re\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= path\n",
    "test_path= path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File(train_path)\n",
    "test_file = bz2.BZ2File(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = train_file.readlines()\n",
    "test_file_lines = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReduceDataset(train,reduce=5):\n",
    "    vector = np.random.choice(len(train), size=len(train)//reduce, replace=False)\n",
    "    vector=list(vector)\n",
    "    \n",
    "    \n",
    "    sentences=pd.DataFrame(train)\n",
    "    \n",
    "    train_sentences = sentences.iloc[vector,:][0]\n",
    "    \n",
    "    return train_sentences\n",
    "\n",
    "train_file_lines = ReduceDataset(train_file_lines, reduce=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[1 if frase.split(\" \")[0] =='__label__1' else 0 for frase in train_file_lines]\n",
    "test_labels=[0 if frase.split(\" \")[0] =='__label__2' else 1 for frase in test_file_lines]\n",
    "\n",
    "\n",
    "train_sentences=[(frase.split(\" \",1)[1].lower()) for frase in train_file_lines]\n",
    "test_sentences=[frase.split(\" \",1)[1].lower() for frase in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    sentences=[]\n",
    "    for text in data:\n",
    "        text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "        sentences.append(text)\n",
    "    return sentences\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences=[re.sub(r'</?a(?:(?= )[^>]*)?>',' ',frase) for frase in test_sentences]\n",
    "test_sentences=[re.sub(r'[^\\w\\s]',' ', frase) for frase in test_sentences] \n",
    "\n",
    "train_sentences=[re.sub(r'</?a(?:(?= )[^>]*)?>',' ',frase) for frase in train_sentences]\n",
    "train_sentences=[re.sub(r'[^\\w\\s]',' ', frase) for frase in train_sentences] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame()\n",
    "df['data'] = train_sentences\n",
    "df['labels'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(train_labels)\n",
    "y_test=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=10000\n",
    "\n",
    "tokenize=Tokenizer(num_words=num_words)\n",
    "\n",
    "tokenize.fit_on_texts(train_sentences)\n",
    "x_train=tokenize.texts_to_sequences(train_sentences)\n",
    "x_test= tokenize.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train_pad=pad_sequences(x_train, maxlen= max_len,padding= \"post\")\n",
    "x_test_pad=pad_sequences(x_test, maxlen= max_len, padding=\"post\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumWords(data):\n",
    "    Numero_palabras=[]\n",
    "    for frase in data:\n",
    "        num_words=len(frase.split(\" \"))\n",
    "        Numero_palabras.append(num_words)\n",
    "    return Numero_palabras\n",
    "\n",
    "def NumChar(data):\n",
    "    num_character=[]\n",
    "    for frase in data:\n",
    "        num_char=len(frase)\n",
    "        num_character.append(num_char)\n",
    "    return num_character\n",
    "\n",
    "\n",
    "\n",
    "Numero_palabras= NumWords(train_sentences)\n",
    "Number_character= NumChar(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr=sns.boxplot(data=Numero_palabras)\n",
    "gr.set_title(\"Number of Words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr=sns.boxplot(data=Number_character)\n",
    "gr.set_title(\"Number of Characters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary= Counter()\n",
    "for frase in train_sentences:\n",
    "    vocabulary.update(list(frase.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(\n",
    "    background_color='white', \n",
    "    max_words=100)\n",
    "\n",
    "wc.generate(' '.join(text for text in df.loc[df['labels'] == 1, 'data']))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.title(\"Negative Review most common words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(\n",
    "    background_color='white', \n",
    "    max_words=100)\n",
    "\n",
    "\n",
    "wc.generate(' '.join(text for text in df.loc[df['labels'] == 0, 'data']))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.title(\"Positive Review most common words\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "First we will create a LSTM model and then we will create a Bert Model and we will compare each other\n",
    "\n",
    "For the LSTM model we will use a GloVe embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings_dictionary = dict()\n",
    "embedding_dim = 100\n",
    "\n",
    "# Load GloVe 100D embeddings\n",
    "with open(\"D:/estudios/GloVe/glove.6B.100d\", encoding='utf-8') as fp:\n",
    "    for line in fp.readlines():\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(tokenize.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "\n",
    "for word, index in tokenize.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid, y_train, y_valid = train_test_split(x_train_pad,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCNN_NLP():\n",
    "    input = Input(shape=(max_len,))\n",
    "    net= (Embedding(input_dim= embedding_matrix.shape[0], output_dim= embedding_matrix.shape[1],weights=[embedding_matrix], input_length=max_len))(input)\n",
    "    net = Dropout(0.2)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    \n",
    "    net = Conv1D(32, 7, padding='same', activation='relu')(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    \n",
    "    net = Conv1D(2, 1)(net)\n",
    "    net = GlobalAveragePooling1D()(net)\n",
    "    output = tf.keras.activations.sigmoid(net)\n",
    "    model = tf.keras.models.Model(inputs = input, outputs = output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "model = FCNN_NLP()\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x_train)\n",
    "x_valid=np.array(x_valid)\n",
    "y_train=np.array(y_train)\n",
    "y_valid=np.array(y_valid)\n",
    "x_test_pad= np.array(x_test_pad)\n",
    "test_labels= np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reduce=8\n",
    "validation_reduce=2\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss', \n",
    "    factor = 1/3, \n",
    "    verbose = 1, \n",
    "    patience = 2,\n",
    "    min_delta=1e-3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train,steps_per_epoch=len(x_train)//model_reduce//32,validation_data=(x_valid,y_valid), validation_steps=len(x_valid)//validation_reduce//32\n",
    ",epochs=50, batch_size=32, callbacks=[EarlyStopping(patience=5, restore_best_weights=True), ModelCheckpoint(\"ModeloLSTM_embedd.h5\", save_best_weights=True), reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_pad,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM\n",
    "We will try a LSTM model with GloVe and without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    model= Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_length, 400))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(max_len, return_sequences=True))) ## if we were using a GPU backend we should remove recurrent dropout\n",
    "    \n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model= LSTM_model()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reduce=8\n",
    "validation_reduce=2\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss', \n",
    "    factor = 0.1, \n",
    "    verbose = 1, \n",
    "    patience = 2,\n",
    "    min_delta=1e-3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,steps_per_epoch=len(x_train)//model_reduce//32,validation_data=(x_valid,y_valid), validation_steps=len(x_valid)//validation_reduce//32\n",
    ",epochs=50, batch_size=32, callbacks=[EarlyStopping(patience=5, restore_best_weights=True), ModelCheckpoint(\"ModeloLSTM_embedd.h5\", save_best_weights=True), reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_pad,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Glove_LSTM():\n",
    "    model= Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim= embedding_matrix.shape[0], output_dim= embedding_matrix.shape[1],weights=[embedding_matrix], input_length=max_len))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(max_len, return_sequences=True))) ## if we were using a GPU backend we should remove recurrent dropout\n",
    "    \n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model= Glove_LSTM()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reduce=8\n",
    "validation_reduce=2\n",
    "\n",
    "history = model.fit(x_train, y_train,steps_per_epoch=len(x_train)//model_reduce//32,validation_data=(x_valid,y_valid), validation_steps=len(x_valid)//validation_reduce//32\n",
    ",epochs=50, batch_size=32, callbacks=[EarlyStopping(patience=5, restore_best_weights=True), ModelCheckpoint(\"ModeloLSTM_GloVe.h5\", save_best_weights=True), reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, path)\n",
    "model.evaluate(x_test_pad,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_model():\n",
    "    model= Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_length, 400))\n",
    "    \n",
    "    model.add(Bidirectional(GRU(max_len, return_sequences=True))) ## if we were using a GPU backend we should remove recurrent dropout\n",
    "    \n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model= GRU_model()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reduce=8\n",
    "validation_reduce=2\n",
    "\n",
    "history = model.fit(x_train, y_train,steps_per_epoch=len(x_train)//model_reduce//32,validation_data=(x_valid,y_valid), validation_steps=len(x_valid)//validation_reduce//32\n",
    ",epochs=50, batch_size=32, callbacks=[EarlyStopping(patience=5, restore_best_weights=True,min_delta= 1e-3), ModelCheckpoint(\"ModeloGRU_embedd.h5\", save_best_weights=True), reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_pad,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Glove_GRU():\n",
    "    model= Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim= embedding_matrix.shape[0], output_dim= embedding_matrix.shape[1],weights=[embedding_matrix], input_length=max_len))\n",
    "    \n",
    "    model.add(Bidirectional(GRU(max_len, return_sequences=True)))\n",
    "    \n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(max_len, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model= Glove_LSTM()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reduce=8\n",
    "validation_reduce=2\n",
    "\n",
    "history = model.fit(x_train, y_train,steps_per_epoch=len(x_train)//model_reduce//32,validation_data=(x_valid,y_valid), validation_steps=len(x_valid)//validation_reduce//32\n",
    ",epochs=50, batch_size=32, callbacks=[EarlyStopping(patience=5, restore_best_weights=True, min_delta= 1e-3), ModelCheckpoint(\"ModeloLSTM.h5\", save_best_weights=True), reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_pad,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_sentences=[re.sub(r'</?a(?:(?= )[^>]*)?>',' ',frase) for frase in test_sentences]\n",
    "test_sentences=[re.sub(r'[^\\w\\s]',' ', frase) for frase in test_sentences] \n",
    "\n",
    "y_test=to_categorical(test_labels)\n",
    "\n",
    "x_test= tokenize.texts_to_sequences(test_sentences)\n",
    "x_test_pad=pad_sequences(x_test, maxlen= max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_NLP_FCNN_GloVe = tf.keras.models.load_model(path)\n",
    "modelo_NLP_GRU_embedd= tf.keras.models.load_model(path)\n",
    "modelo_NLP_LSTM_embedd= tf.keras.models.load_model(path)\n",
    "modelo_NLP_LSTM_GloVe= tf.keras.models.load_model(path)\n",
    "modelo_NLP_GRU_GloVe= tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_NLP_FCNN_GloVe.evaluate(x_test_pad, y_test)\n",
    "\n",
    "modelo_NLP_GRU_embedd.evaluate(x_test_pad, y_test)\n",
    "\n",
    "modelo_NLP_LSTM_embedd.evaluate(x_test_pad, y_test)\n",
    "\n",
    "modelo_NLP_LSTM_GloVe.evaluate(x_test_pad, y_test)\n",
    "\n",
    "modelo_NLP_GRU_GloVe.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1= \"The product was fantastic, very useful\"\n",
    "sentence2= \"Just a waste of money I don't recommened anyone to buy this book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = re.sub(r'</?a(?:(?= )[^>]*)?>',' ',sentence1)\n",
    "sentence2 = re.sub(r'[^\\w\\s]',' ', sentence2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=[(sentence1.split(\" \",1)[1].lower())]\n",
    "sentence2=[sentence2.split(\" \",1)[1].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=tokenize.texts_to_sequences(sentence1)\n",
    "sentence2=tokenize.texts_to_sequences(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=pad_sequences(sentence1, maxlen= max_len,padding= \"post\")\n",
    "sentence2=pad_sequences(sentence2, maxlen= max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(modelo_NLP_FCNN_GloVe.predict(sentence1)))\n",
    "print(np.amax(modelo_NLP_FCNN_GloVe.predict(sentence1))) ## with 97 % confidence it's a good review\n",
    "\n",
    "print(np.argmax(modelo_NLP_FCNN_GloVe.predict(sentence2)))\n",
    "print(np.amax(modelo_NLP_FCNN_GloVe.predict(sentence2))) ## with 98% confidence it's a bad review\n",
    "\n",
    "\n",
    "## Looks like it works !!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
